{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks (CNNs)\n",
    "\n",
    "This notebook provides an introduction to Convolutional Neural Networks (CNNs), covering their components, mathematical foundations, and applications in image processing and computer vision.\n",
    "\n",
    "---\n",
    "\n",
    "### Table of Contents\n",
    "1. **Introduction to CNNs**\n",
    "2. **CNNs and Their Components**\n",
    "3. **Convolution Operation**\n",
    "4. **Pooling Layers**\n",
    "5. **Fully Connected Layers**\n",
    "6. **Applications in Image Processing and Computer Vision**\n",
    "7. **Example: Building a CNN with TensorFlow/Keras**\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Introduction to CNNs\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are a class of deep learning models specifically designed for processing grid-like data, such as images. CNNs leverage spatial hierarchies of features to automatically and adaptively learn patterns from data.\n",
    "\n",
    "### Why CNNs for Images?\n",
    "- **Local Receptive Fields:** CNNs focus on small regions of an image, capturing local patterns like edges, textures, and shapes.\n",
    "- **Parameter Sharing:** Convolutional filters are shared across the image, reducing the number of parameters compared to fully connected networks.\n",
    "- **Translation Invariance:** CNNs can recognize patterns regardless of their position in the image.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. CNNs and Their Components\n",
    "\n",
    "CNNs consist of the following key components:\n",
    "1. **Convolutional Layers:** Extract features from input images using filters.\n",
    "2. **Pooling Layers:** Reduce spatial dimensions while retaining important information.\n",
    "3. **Fully Connected Layers:** Combine features for final classification or regression.\n",
    "\n",
    "---\n",
    "\n",
    "## 3. Convolution Operation\n",
    "\n",
    "### Mathematical Explanation\n",
    "Convolution is a mathematical operation used in Convolutional Neural Networks (CNNs) to extract features from an image. The convolution operation involves sliding a filter (kernel) over the input image to produce a feature map. Mathematically, it is expressed as:\n",
    "\n",
    "$\\[\n",
    "\\text{Output}(i, j) = \\sum_{m=0}^{k-1} \\sum_{n=0}^{k-1} \\text{Input}(i+m, j+n) \\cdot \\text{Filter}(m, n)\n",
    "\\]$\n",
    "\n",
    "Where:\n",
    "- $\\( \\text{Input} \\)$ is the input image.\n",
    "- $\\( \\text{Filter} \\)$ is the kernel (e.g., 3x3 or 5x5 matrix).\n",
    "- $\\( k \\)$ is the size of the filter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Map:\n",
      " [[-6. -6. -6.]\n",
      " [-6. -6. -6.]\n",
      " [-6. -6. -6.]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Input image (5x5)\n",
    "input_image = np.array([\n",
    "    [1, 2, 3, 4, 5],\n",
    "    [6, 7, 8, 9, 10],\n",
    "    [11, 12, 13, 14, 15],\n",
    "    [16, 17, 18, 19, 20],\n",
    "    [21, 22, 23, 24, 25]\n",
    "])\n",
    "\n",
    "# Filter (3x3)\n",
    "filter_kernel = np.array([\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1],\n",
    "    [1, 0, -1]\n",
    "])\n",
    "\n",
    "# Convolution function\n",
    "def convolution2d(image, kernel):\n",
    "    kernel_size = kernel.shape[0]\n",
    "    output_size = image.shape[0] - kernel_size + 1\n",
    "    output = np.zeros((output_size, output_size))\n",
    "    \n",
    "    for i in range(output_size):\n",
    "        for j in range(output_size):\n",
    "            output[i, j] = np.sum(image[i:i+kernel_size, j:j+kernel_size] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Apply convolution\n",
    "feature_map = convolution2d(input_image, filter_kernel)\n",
    "print(\"Feature Map:\\n\", feature_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Map with Zero Padding:\n",
      " [[ -9.  -4.  -4.  -4.  13.]\n",
      " [-21.  -6.  -6.  -6.  27.]\n",
      " [-36.  -6.  -6.  -6.  42.]\n",
      " [-51.  -6.  -6.  -6.  57.]\n",
      " [-39.  -4.  -4.  -4.  43.]]\n"
     ]
    }
   ],
   "source": [
    "def convolution2d_with_padding(image, kernel, padding=1):\n",
    "    kernel_size = kernel.shape[0]\n",
    "    padded_image = np.pad(image, pad_width=padding, mode='constant', constant_values=0)\n",
    "    output_size = image.shape[0]\n",
    "    output = np.zeros((output_size, output_size))\n",
    "    \n",
    "    for i in range(output_size):\n",
    "        for j in range(output_size):\n",
    "            output[i, j] = np.sum(padded_image[i:i+kernel_size, j:j+kernel_size] * kernel)\n",
    "    \n",
    "    return output\n",
    "\n",
    "# Apply convolution with zero padding\n",
    "feature_map_padded = convolution2d_with_padding(input_image, filter_kernel)\n",
    "print(\"Feature Map with Zero Padding:\\n\", feature_map_padded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Example Scenario: Edge Detection**\n",
    "- We take a **3×3 Sobel filter** for detecting horizontal edges.\n",
    "- The **input matrix** represents a 5×5 grayscale image.\n",
    "\n",
    "#### **Input Image (5×5)**\n",
    "\\[\n",
    "\\begin{bmatrix}\n",
    "10 & 10 & 20 & 30 & 40 \\\\\n",
    "20 & 30 & 40 & 50 & 60 \\\\\n",
    "30 & 40 & 50 & 60 & 70 \\\\\n",
    "40 & 50 & 60 & 70 & 80 \\\\\n",
    "50 & 60 & 70 & 80 & 90\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "#### **Filter (3×3 Sobel Horizontal Edge Detector)**\n",
    "\\[\n",
    "\\begin{bmatrix}\n",
    "-1 & -2 & -1 \\\\\n",
    "0 & 0 & 0 \\\\\n",
    "1 & 2 & 1\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "#### **Convolution Process (Stride = 1)**\n",
    "We slide the 3×3 filter over the input image and compute the **dot product** at each position. Let’s compute a few steps:\n",
    "\n",
    "- **Step 1: Top-left region**\n",
    "  - Extracted region:\n",
    "    \\[\n",
    "    \\begin{bmatrix}\n",
    "    10 & 10 & 20 \\\\\n",
    "    20 & 30 & 40 \\\\\n",
    "    30 & 40 & 50\n",
    "    \\end{bmatrix}\n",
    "    \\]\n",
    "  - Compute convolution:\n",
    "    \\[\n",
    "    (10×-1) + (10×-2) + (20×-1) + (20×0) + (30×0) + (40×0) + (30×1) + (40×2) + (50×1) = -10 - 20 - 20 + 30 + 80 + 50 = 110\n",
    "    \\]\n",
    "  - Result for this region: **110**\n",
    "\n",
    "Applying this to the whole input, we obtain a **3×3 feature map**.\n",
    "\n",
    "#### **Feature Map (After Convolution)**\n",
    "\\[\n",
    "\\begin{bmatrix}\n",
    "110 & 150 & 190 \\\\\n",
    "150 & 190 & 230 \\\\\n",
    "190 & 230 & 270\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pooling Layers\n",
    "\n",
    "Pooling layers reduce the spatial dimensions of feature maps while retaining important information. Common types include:\n",
    "- **Max Pooling:** Selects the maximum value in each window.\n",
    "- **Average Pooling:** Computes the average value in each window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pooled Output:\n",
      " [[ 1  2  3  4  5]\n",
      " [ 6  7  8  9 10]\n",
      " [11 12 13 14 15]\n",
      " [16 17 18 19 20]\n",
      " [21 22 23 24 25]]\n",
      "Pooled Output:\n",
      " [[ 7.  9.]\n",
      " [17. 19.]]\n"
     ]
    }
   ],
   "source": [
    "def max_pooling2d(image, pool_size=2, stride=2):\n",
    "    output_size = (image.shape[0] - pool_size) // stride + 1\n",
    "    output = np.zeros((output_size, output_size))\n",
    "    \n",
    "    for i in range(0, output_size):\n",
    "        for j in range(0, output_size):\n",
    "            output[i, j] = np.max(image[i*stride:i*stride+pool_size, j*stride:j*stride+pool_size])\n",
    "    \n",
    "    return output\n",
    "\n",
    "\n",
    "print(\"Pooled Output:\\n\", input_image)\n",
    "# Apply max pooling\n",
    "pooled_output = max_pooling2d(input_image)\n",
    "print(\"Pooled Output:\\n\", pooled_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Max Pooling\n",
    "\n",
    "Pooling reduces the dimensions of the feature map while preserving important information.\n",
    "\n",
    "#### **Max Pooling (2×2, Stride = 2)**\n",
    "We take the maximum value in each 2×2 region.\n",
    "\n",
    "#### **Feature Map (Before Pooling)**\n",
    "\\[\n",
    "\\begin{bmatrix}\n",
    "110 & 150 & 190 \\\\\n",
    "150 & 190 & 230 \\\\\n",
    "190 & 230 & 270\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "#### **After Max Pooling (2×2)**\n",
    "\\[\n",
    "\\begin{bmatrix}\n",
    "190 & 230 \\\\\n",
    "230 & 270\n",
    "\\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "\n",
    "1. **Convolution extracts features (edges, textures, etc.).**\n",
    "2. **Pooling reduces spatial dimensions while preserving important features.**\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Fully Connected Layers\n",
    "\n",
    "Fully connected layers combine the features extracted by convolutional and pooling layers to produce the final output. Each neuron in a fully connected layer is connected to every neuron in the previous layer.\n",
    "\n",
    "```import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Define a fully connected layer\n",
    "fc_layer = layers.Dense(units=10, activation='softmax')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Applications in Image Processing and Computer Vision\n",
    "\n",
    "CNNs are widely used in:\n",
    "- **Image Classification:** Assigning labels to images (e.g., CIFAR-10, ImageNet).\n",
    "- **Object Detection:** Identifying and localizing objects in images (e.g., YOLO, Faster R-CNN).\n",
    "- **Image Segmentation:** Partitioning images into regions (e.g., U-Net, Mask R-CNN).\n",
    "- **Face Recognition:** Identifying individuals from images (e.g., FaceNet).\n",
    "\n",
    "---\n",
    "\n",
    "## 7. Example: Building a CNN with TensorFlow/Keras\n",
    "\n",
    "Let's build a simple CNN for image classification using the CIFAR-10 dataset.\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to [0, 1]\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# Define CNN architecture\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f\"Test Accuracy: {test_acc}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary\n",
    "This notebook introduced the fundamental concepts of CNNs, including their components, mathematical foundations, and applications. We also implemented a simple CNN using TensorFlow/Keras for image classification.\n",
    "\n",
    "---\n",
    "\n",
    "### Next Steps\n",
    "- Experiment with different CNN architectures.\n",
    "- Explore advanced topics like transfer learning and data augmentation.\n",
    "- Apply CNNs to real-world datasets and problems.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
